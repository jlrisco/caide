{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "CV2e-LsWOe-k"
   },
   "source": [
    "# CSV 2 H5\n",
    "\n",
    "Let's transform CSV sensor data to H5 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary class:\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import os\n",
    "import tables as tb\n",
    "\n",
    "class DataUtils:\n",
    "    \"\"\"Class for data utilities.\"\"\"\n",
    "    \n",
    "    class SensorData(tb.IsDescription):\n",
    "        \"\"\"Class to define the structure of the table in the HDF5 file.\"\"\"\n",
    "\n",
    "        timestamp = tb.Time64Col(pos=0)\n",
    "        radiation = tb.Float32Col(pos=1)    # Radiation, W/m2\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def transform_oahu_data_to_h5(self, base_folder: str, data_center_name: str, farm_name: str, sensor_names: list[str], sensor_latitudes: list[float], sensor_longitudes: list[float]):\n",
    "        # Let's create the h5 file\n",
    "        h5_file = tb.open_file(f'{base_folder}/{farm_name}/sensors_data.h5', 'w')\n",
    "        # Now, we create the group for the farm:\n",
    "        info_group = h5_file.create_group('/', 'info', 'Basic information')\n",
    "        data_group = h5_file.create_group('/', 'data', 'Sensor data')\n",
    "        # In the following we add tables regarding sensor names, latitudes and longitudes\n",
    "        h5_file.create_array(info_group, 'sensor_names', sensor_names)\n",
    "        h5_file.create_array(info_group, 'sensor_latitudes', np.array(sensor_latitudes))\n",
    "        h5_file.create_array(info_group, 'sensor_longitudes', np.array(sensor_longitudes))\n",
    "        for sensor_name in sensor_names:\n",
    "            sensor_file_paths: list = []\n",
    "            for file_name in os.listdir(f'{base_folder}/{data_center_name}/{farm_name}/{sensor_name}'):\n",
    "                file_path: str = os.path.join(f'{base_folder}/{data_center_name}/{farm_name}/{sensor_name}', file_name)\n",
    "                if os.path.isfile(file_path):\n",
    "                    sensor_file_paths.append(file_path)\n",
    "                    print(f'Storing file path {file_path} ...')\n",
    "            sensor_file_paths.sort()\n",
    "            # Now, we create the table for the sensor\n",
    "            table = h5_file.create_table(data_group, sensor_name, DataUtils.SensorData, f'Sensor {sensor_name} data')\n",
    "            # ... and add all the CSV data to the table\n",
    "            for sensor_file_path in sensor_file_paths:\n",
    "                print(f'Processing file {sensor_file_path} ...')\n",
    "                reader = open(sensor_file_path, 'r')\n",
    "                reader.readline()  # Nos saltamos la cabecera\n",
    "                for line in reader:\n",
    "                    parts: list = line.split(',')\n",
    "                    sensor_data = table.row\n",
    "                    sensor_data['timestamp'] = dt.datetime.strptime(parts[0], '%Y-%m-%d %H:%M:%S-10:00').timestamp()\n",
    "                    sensor_data['radiation'] = float(parts[1])\n",
    "                    sensor_data.append()\n",
    "                reader.close()\n",
    "            table.flush()\n",
    "        h5_file.close()\n",
    "\n",
    "    def transform_pvgis_data_to_h5(self, base_folder: str, farm_name: str, sensor_names: list[str], sensor_latitudes: list[float], sensor_longitudes: list[float]):\n",
    "        # Let's create the h5 file\n",
    "        h5_file = tb.open_file(f'{base_folder}/{farm_name}/sensors_data.h5', 'w')\n",
    "        # Now, we create the group for the farm:\n",
    "        info_group = h5_file.create_group('/', 'info', 'Basic information')\n",
    "        data_group = h5_file.create_group('/', 'data', 'Sensor data')\n",
    "        # In the following we add tables regarding sensor names, latitudes and longitudes\n",
    "        h5_file.create_array(info_group, 'sensor_names', sensor_names)\n",
    "        h5_file.create_array(info_group, 'sensor_latitudes', np.array(sensor_latitudes))\n",
    "        h5_file.create_array(info_group, 'sensor_longitudes', np.array(sensor_longitudes))\n",
    "        for sensor_name in sensor_names:\n",
    "            sensor_file_path = f'{base_folder}/{farm_name}/{sensor_name}.csv'\n",
    "            # Now, we create the table for the sensor\n",
    "            table = h5_file.create_table(data_group, sensor_name, DataUtils.SensorData, f'Sensor {sensor_name} data')\n",
    "            # ... and add all the CSV data to the table\n",
    "            print(f'Processing file {sensor_file_path} ...')\n",
    "            reader = open(sensor_file_path, 'r')\n",
    "            # We jump the first 9 lines\n",
    "            for _ in range(9):\n",
    "                reader.readline()\n",
    "            for line in reader:\n",
    "                # Break the loop when line is empty\n",
    "                if line == '\\n':\n",
    "                    break\n",
    "                parts: list = line.split(',')\n",
    "                sensor_data = table.row\n",
    "                sensor_data['timestamp'] = dt.datetime.strptime(parts[0], '%Y%m%d:%H%M').timestamp()\n",
    "                sensor_data['radiation'] = float(parts[1])\n",
    "                sensor_data.append()\n",
    "            reader.close()\n",
    "            table.flush()\n",
    "        h5_file.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1676372675601,
     "user": {
      "displayName": "José Luis Risco Martín",
      "userId": "06928831527877695592"
     },
     "user_tz": -60
    },
    "id": "05jDvtX1JM_h",
    "outputId": "d7f08af5-3829-46fc-d14d-60f0f2530668"
   },
   "outputs": [],
   "source": [
    "sensor_names = []\n",
    "# Build sensor names in the format sensor01, sensor02, etc.\n",
    "for i in range(1, 19):\n",
    "    sensor_names.append(\"sensor\" + str(i).zfill(2))\n",
    "sensor_latitudes: list[float] = [36.875, 36.875, 36.875, 36.875, 36.875, 36.875, 36.874, 36.874, 36.874, 36.874, 36.874, 36.874, 36.873, 36.873, 36.873, 36.873, 36.873, 36.873]\n",
    "sensor_longitudes: list[float] = [-2.594, -2.593, -2.592, -2.591, -2.590, -2.589, -2.594, -2.593, -2.592, -2.591, -2.590, -2.589, -2.594, -2.593, -2.592, -2.591, -2.590, -2.589]\n",
    "base_folder = '../data/input'\n",
    "farm_name = 'Almeria'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "tKDHrIVmJfCz"
   },
   "source": [
    "Let's transform the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34557,
     "status": "ok",
     "timestamp": 1676372712940,
     "user": {
      "displayName": "José Luis Risco Martín",
      "userId": "06928831527877695592"
     },
     "user_tz": -60
    },
    "id": "hKzPVYXpOwjq",
    "outputId": "986287eb-adb9-4e0e-ce96-c530f93a6d38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file ../data/input/Almeria/sensor01.csv ...\n",
      "Processing file ../data/input/Almeria/sensor02.csv ...\n",
      "Processing file ../data/input/Almeria/sensor03.csv ...\n",
      "Processing file ../data/input/Almeria/sensor04.csv ...\n",
      "Processing file ../data/input/Almeria/sensor05.csv ...\n",
      "Processing file ../data/input/Almeria/sensor06.csv ...\n",
      "Processing file ../data/input/Almeria/sensor07.csv ...\n",
      "Processing file ../data/input/Almeria/sensor08.csv ...\n",
      "Processing file ../data/input/Almeria/sensor09.csv ...\n",
      "Processing file ../data/input/Almeria/sensor10.csv ...\n",
      "Processing file ../data/input/Almeria/sensor11.csv ...\n",
      "Processing file ../data/input/Almeria/sensor12.csv ...\n",
      "Processing file ../data/input/Almeria/sensor13.csv ...\n",
      "Processing file ../data/input/Almeria/sensor14.csv ...\n",
      "Processing file ../data/input/Almeria/sensor15.csv ...\n",
      "Processing file ../data/input/Almeria/sensor16.csv ...\n",
      "Processing file ../data/input/Almeria/sensor17.csv ...\n",
      "Processing file ../data/input/Almeria/sensor18.csv ...\n",
      "2019-01-01 00:09:00\n",
      "0.0\n",
      "2019-01-01 01:09:00\n",
      "0.0\n",
      "2019-01-01 02:09:00\n",
      "0.0\n",
      "2019-01-01 03:09:00\n",
      "0.0\n",
      "2019-01-01 04:09:00\n",
      "0.0\n",
      "2019-01-01 05:09:00\n",
      "0.0\n",
      "2019-01-01 06:09:00\n",
      "0.0\n",
      "2019-01-01 07:09:00\n",
      "0.0\n",
      "2019-01-01 08:09:00\n",
      "247.97\n",
      "2019-01-01 09:09:00\n",
      "556.96\n"
     ]
    }
   ],
   "source": [
    "data_utils = DataUtils()\n",
    "data_utils.transform_pvgis_data_to_h5(base_folder, farm_name, sensor_names, sensor_latitudes, sensor_longitudes)\n",
    "# Let's print firt row of ap1 table\n",
    "h5_file = tb.open_file(f'{base_folder}/{farm_name}/sensors_data.h5', 'r')\n",
    "table = h5_file.root.data.sensor01\n",
    "for i in range(0, 10):\n",
    "    print(dt.datetime.fromtimestamp(table[i]['timestamp']).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    print(table[i]['radiation'])\n",
    "h5_file.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM2qLGjEwdSsInW54MC/tuP",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
